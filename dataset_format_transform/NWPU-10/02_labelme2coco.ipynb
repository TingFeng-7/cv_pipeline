{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import json\n",
    "import os\n",
    "from os.path import join as pathj\n",
    "import datetime\n",
    "# from loguru import logger\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "def ensure_dir(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    return folder\n",
    "\n",
    "def line2str(l):\n",
    "    str1=''\n",
    "    for ele in l[0:-1]:\n",
    "        str1 = str1 + str(ele)+' '\n",
    "    return str1 + str(l[-1])\n",
    "\n",
    "def gen_class2id(classes):\n",
    "    cls2id = {}\n",
    "    for k,v in enumerate(classes):\n",
    "        cls2id[v] = k\n",
    "    return cls2id\n",
    "\n",
    "def xyxy2xywh(box):\n",
    "    x1 = min(box[0], box[2])\n",
    "    y1 = min(box[1], box[3])\n",
    "    w = abs(box[2]-box[0])\n",
    "    h = abs(box[3]-box[1])\n",
    "    return [x1, y1, w, h, w*h]\n",
    "\n",
    "def gen_empty_cocojson_instance(class_name_en):\n",
    "    # 创建 总标签data \n",
    "    now = datetime.datetime.now()\n",
    "    instance = dict(\n",
    "        info=dict(\n",
    "            description=None,\n",
    "            url=None,\n",
    "            version=None,\n",
    "            year=now.year,\n",
    "            contributor=None,\n",
    "            date_created=now.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n",
    "        ),\n",
    "        licenses=[dict(url=None, id=0, name=None,)],\n",
    "        images=[\n",
    "            # license, url, file_name, height, width, date_captured, id\n",
    "        ],\n",
    "        type=\"instances\",\n",
    "        annotations=[\n",
    "            # segmentation, area, iscrowd, image_id, bbox, category_id, id\n",
    "        ],\n",
    "        categories = gen_category_dict(class_name_en),\n",
    "        # categories=[\n",
    "        #     # supercategory, id, name\n",
    "        # ],\n",
    "    )\n",
    "\n",
    "    return instance\n",
    "\n",
    "def gen_one_image_dict(img_name, h, w, id):\n",
    "    data = {\n",
    "        'file_name': os.path.basename(img_name),\n",
    "        'height': h,\n",
    "        'width': w,\n",
    "        'id': id        \n",
    "    }\n",
    "    return data\n",
    "\n",
    "def gen_one_anno_dict(cat_id, img_id, bbox: list, area, anno_id):\n",
    "    anno = {\n",
    "        'segmentation':[],\n",
    "        'area': area, #直接取绝对值\n",
    "        'iscrowd': 0,\n",
    "        'image_id': img_id,\n",
    "        'bbox': bbox,\n",
    "        'category_id': cat_id,   \n",
    "        'id': anno_id\n",
    "\n",
    "    }\n",
    "    return anno\n",
    "    \n",
    "def gen_category_dict(class_name):\n",
    "    ins = []\n",
    "    for k,v in enumerate(class_name):\n",
    "        one_cate = {'id':k, 'name':v,'supercategory':v}\n",
    "        ins.append(one_cate) \n",
    "    return ins\n",
    "\n",
    "def read_txt(abs_txt_name):\n",
    "    with open(abs_txt_name,'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "                line = line.replace(')','').replace('(','')\n",
    "                row = line.strip().split(',')\n",
    "                print(row)\n",
    "# 读取json\n",
    "def read_json(abs_txt_name):\n",
    "    with open(abs_txt_name, 'r', encoding='utf-8') as f: #读文件名\n",
    "        ret_dic = json.load(f)\n",
    "        return ret_dic\n",
    "        \n",
    "def save_json(new_name,json_ins):\n",
    "    with open(new_name, 'w',encoding='utf-8') as f:\n",
    "        json.dump(json_ins ,f ,indent=2,ensure_ascii=False)#zw\n",
    "        print('{} saved'.format(new_name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir =r'D:\\sa_data\\0011_v1.6_filtered_linebox_yolox\\labelme\\imgs'\n",
    "img_names = [x for x in os.listdir(pathj(tmp_dir, './')) if x.endswith('png')]\n",
    "json_names = [x for x in os.listdir(pathj(tmp_dir, './')) if x.endswith('json')]\n",
    "\n",
    "text_list = ['icontext','text','icon_text','text_icon_','icon_question_'] # text_icon的所有系类别\n",
    "image_list = ['image', 'icon','icon_']\n",
    "# op = ['add', 'arrow','close','cross','magnifier', 'minimize','maximize','question','search','selectBox']\n",
    "linebox_list =['inputbox', 'tab', 'linebox'] #, 'scrollbar_slider','track'\n",
    "line_list = ['v_segline', 'h_segline', 'scrollbar_slider', 'track']\n",
    "#labelme目录中 同时有图片和json\n",
    "cate2finecate={'text':text_list, 'icon':image_list, 'linebox': linebox_list}\n",
    "# cate2finecate4={'text':text_list, 'image':image_list, 'linebox': linebox_list, 'line': line_list}\n",
    "cate2finecate4={'linebox': linebox_list, 'line': line_list}\n",
    "class_name_en_3 = ['text', 'icon', 'linebox'] # 暂时还是叫icon\n",
    "# class_name_en_4 = ['text', 'image', 'linebox', 'line']\n",
    "# class_name_en_4 = ['linebox', 'line']\n",
    "# text如果满足了就是 text的其余都是image的 icon\n",
    "def finecate_to_basecate(cls, cls_map:dict):\n",
    "    keys = cls_map.keys()\n",
    "    # print(keys)\n",
    "    for key in keys:\n",
    "        for i in cls_map[key]:\n",
    "            if cls == i or i in cls:\n",
    "                return key\n",
    "    return 'no'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cls = set()\n",
    "label_list =[]\n",
    "for name in json_names:\n",
    "    ins = read_json(pathj(tmp_dir, name))\n",
    "    for one in ins['shapes']:\n",
    "        cate = finecate_to_basecate(one['label'], cate2finecate)\n",
    "        if cate == 'no':\n",
    "            continue\n",
    "        else:\n",
    "            cls.add(cate)\n",
    "            label_list.append(cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'text': 793792, 'icon': 455580, 'linebox': 40364})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count =Counter(label_list)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_names = []\n",
    "for name in img_names:\n",
    "    file_names.append(name)\n",
    "file_names = np.array(file_names)\n",
    "np.random.seed(777)\n",
    "np.random.shuffle(file_names)\n",
    "# 0.85 : 0.15\n",
    "end = int(len(file_names)*0.85)\n",
    "\n",
    "t_name = file_names[:end].tolist()\n",
    "v_name = file_names[end:].tolist()\n",
    "#打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "coco_ins = gen_empty_cocojson_instance(class_name_en_3)\n",
    "\n",
    "import copy\n",
    "val_coco_ins = copy.deepcopy(coco_ins)\n",
    "# print(coco_ins['categories'])\n",
    "# os.path.basename('sdsd\\sdsds\\asdasd\\l.ll')\n",
    "class_name_en_3.index('linebox')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total transform: 1091065\n",
      "min:10, max:0\n"
     ]
    }
   ],
   "source": [
    "#--- folder path：data目录\n",
    "root_dir =r'D:\\sa_data\\0011_v1.6_filtered_linebox_yolox\\labelme\\imgs'\n",
    "# D:\\sa_data\\other\\NWPU VHR-10 dataset\\gtwithimg\n",
    "#'#保存路径 images,labels\n",
    "\n",
    "img_part = coco_ins['images']\n",
    "anno_part = coco_ins['annotations']\n",
    "\n",
    "name_id = 0\n",
    "anno_id = 0\n",
    "anno_count =0\n",
    "max_det= 0\n",
    "min_det =10\n",
    "\n",
    "json_names = [x for x in os.listdir(root_dir) if x.endswith('json')]\n",
    "#遍历每个 json 文件\n",
    "for name in json_names:\n",
    "\n",
    "    file_path = os.path.join(root_dir,name)\n",
    "    img_name = file_path[:-5]+'.png'\n",
    "    if name[:-5]+'.png' not in t_name: \n",
    "        continue\n",
    "    txt =[]\n",
    "    img = cv2.imread(img_name, flags=cv2.IMREAD_COLOR)\n",
    "    # images\n",
    "    name_id += 1\n",
    "    data_ins = gen_one_image_dict(img_name, img.shape[0], img.shape[1], name_id)\n",
    "    img_part.append(data_ins) #宽高、名字\n",
    "    # img = Image.open(img_name)#txt怎么取名的这个问题\n",
    "    # load labelme json\n",
    "    labelme_ins = read_json(file_path)\n",
    "    shapes = labelme_ins['shapes']\n",
    "    per_img_annos_count = 0\n",
    "    for shape in shapes:\n",
    "        # print(shape)\n",
    "        cate = finecate_to_basecate(shape['label'], cate2finecate)\n",
    "        if cate == 'no':\n",
    "            continue\n",
    "        else:\n",
    "            x1,y1 = shape['points'][0]\n",
    "            x2,y2 = shape['points'][1]\n",
    "            bbox =xyxy2xywh([x1,y1,x2,y2])\n",
    "            # label_list.append(cate)\n",
    "            cls_id = class_name_en_3.index(cate) # 最后一行纯数字 id从1开始\n",
    "            anno_id+=1\n",
    "            anno_ins = gen_one_anno_dict(cls_id, name_id, bbox[:4], bbox[4], anno_id)\n",
    "            anno_part.append(anno_ins) #宽高、名字\n",
    "            per_img_annos_count+=1\n",
    "\n",
    "    # if per_img_annos_count>0:\n",
    "    #     name_id += 1\n",
    "    #     data_ins = gen_one_image_dict(img_name, img.shape[0], img.shape[1], name_id)\n",
    "    #     anno_part.append(data_ins)\n",
    "\n",
    "print('total transform: %s'% (anno_id))\n",
    "print(f'min:{min_det}, max:{max_det}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total transform: 198671\n",
      "min:10, max:0\n"
     ]
    }
   ],
   "source": [
    "# 验证集\n",
    "val_img_part = val_coco_ins['images']\n",
    "val_anno_part = val_coco_ins['annotations']\n",
    "\n",
    "name_id = 0\n",
    "anno_id = 0\n",
    "anno_count =0\n",
    "max_det= 0\n",
    "min_det =10\n",
    "\n",
    "json_names = [x for x in os.listdir(root_dir) if x.endswith('json')]\n",
    "#遍历每个 json 文件\n",
    "for name in json_names:\n",
    "\n",
    "    file_path = os.path.join(root_dir,name)\n",
    "    img_name = file_path[:-5]+'.png'\n",
    "    if name[:-5]+'.png' not in v_name: # if name in trainning set\n",
    "        continue\n",
    "    txt =[]\n",
    "    img = cv2.imread(img_name, flags=cv2.IMREAD_COLOR)\n",
    "    # img = Image.open(img_name)#txt怎么取名的这个问题\n",
    "    name_id += 1\n",
    "    data_ins = gen_one_image_dict(img_name, img.shape[0], img.shape[1], name_id)\n",
    "    val_img_part.append(data_ins) #宽高、名字\n",
    "    # load labelme json\n",
    "    labelme_ins = read_json(file_path)\n",
    "    shapes = labelme_ins['shapes']\n",
    "    for shape in shapes:\n",
    "        # print(shape)\n",
    "        cate = finecate_to_basecate(shape['label'], cate2finecate)\n",
    "        if cate == 'no':\n",
    "            continue\n",
    "        else:\n",
    "            x1,y1 = shape['points'][0]\n",
    "            x2,y2 = shape['points'][1]\n",
    "            bbox =xyxy2xywh([x1,y1,x2,y2])\n",
    "            # label_list.append(cate)\n",
    "            cls_id = class_name_en_3.index(cate) # 最后一行纯数字 id从1开始\n",
    "            anno_id+=1\n",
    "            anno_ins = gen_one_anno_dict(cls_id, name_id, bbox[:4], bbox[4], anno_id)\n",
    "            val_anno_part.append(anno_ins) #宽高、名字\n",
    "            \n",
    "        img_part.append(data_ins) #宽高、名字\n",
    "print('total transform: %s'% (anno_id))\n",
    "print(f'min:{min_det}, max:{max_det}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(val_coco_ins['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\sa_data\\0011_v1.6_filtered_linebox_yolox\\labelme\\imgs\\../val_v1.6.json saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dir = root_dir\n",
    "save_json(pathj(save_dir, '../',\"val_v1.6.json\"), val_coco_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\sa_data\\0011_v1.6_filtered_linebox_yolox\\labelme\\imgs\\../train_v1.6.json saved\n"
     ]
    }
   ],
   "source": [
    "save_dir = root_dir\n",
    "save_json(pathj(save_dir, '../',\"train_v1.6.json\"), coco_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      "  0: text\n",
      "  1: image\n",
      "  2: linebox\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "c = {'names':{}}\n",
    "for k,v in enumerate(class_name_en):\n",
    "    c['names'][k] = v\n",
    "print(yaml.dump(c, allow_unicode=True))\n",
    "with open('b1.yaml', 'w') as file:\n",
    "    file.write(yaml.dump(c, allow_unicode=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
