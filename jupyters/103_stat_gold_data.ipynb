{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os.path import join as pathj\n",
    "root_dir = r'D:\\sa_data\\f36_exps\\20221124_aware_hardnms_conf10_iou50\\Element_grabbing\\grabbing_evaluation\\labelme\\grabbing_evaluation_statistics\\statistic_0.5_0.5_0.5_0\\detect'\n",
    "miss = 'button_miss' #有label\n",
    "fault = 'button_fault'\n",
    "miss_dir = os.path.join(root_dir,miss)\n",
    "fault_dir = os.path.join(root_dir,fault)\n",
    "# 读取json\n",
    "def read_json(abs_txt_name):\n",
    "    with open(abs_txt_name, 'r', encoding='utf-8') as f: #读文件名\n",
    "        ret_dic = json.load(f)\n",
    "        return ret_dic\n",
    "        \n",
    "def save_json(new_name,json_ins):\n",
    "    with open(new_name, 'w',encoding='utf-8') as f:\n",
    "        json.dump(json_ins ,f ,indent=2,ensure_ascii=False)#zw\n",
    "        print('{} saved'.format(new_name)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.统计labelme的分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.统计sa的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigger20_dir\n",
      "smaller10_dir\n",
      "smaller20_dir\n"
     ]
    }
   ],
   "source": [
    "gold_dir = r'D:\\sa_split_30'\n",
    "gold_dir = r'D:\\sa_data\\sa_coco_1' #gold\n",
    "gold_dir = r'D:\\20221206_aware_hardnms_conf10_iou50\\Element_grabbing\\grabbing_evaluation'\n",
    "stat_dict ={}\n",
    "class_name = [] \n",
    "# cls_map = {'text':['icon_text'],\n",
    "#                 'icon':['arrow','mohu'],\n",
    "#                 'linebox':['inputbox','scrollbar_slider', 'track', 'h_segline', 'v_segline', 'tab', 'linebox']}\n",
    "\n",
    "class_name = ['text','icon','image','linebox'] \n",
    "for sub in os.listdir(gold_dir):\n",
    "    print(sub)\n",
    "    json_dir = pathj(gold_dir, sub, 'grabbing_predict')\n",
    "    if os.path.isdir(json_dir):\n",
    "        for cls in class_name:\n",
    "                stat_dict[sub+'_'+cls+'_gold'] = 0 #初始化先\n",
    "        for filename in os.listdir(json_dir):\n",
    "            ins = read_json(pathj(json_dir, filename))\n",
    "            for cls in class_name:\n",
    "                stat_dict[sub+'_'+cls+'_gold'] += len(ins[cls])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"bigger20_dir_icon_gold\": 230,\n",
      "    \"bigger20_dir_image_gold\": 42,\n",
      "    \"bigger20_dir_linebox_gold\": 38155,\n",
      "    \"bigger20_dir_text_gold\": 2641,\n",
      "    \"smaller10_dir_icon_gold\": 457010,\n",
      "    \"smaller10_dir_image_gold\": 11692,\n",
      "    \"smaller10_dir_linebox_gold\": 60245,\n",
      "    \"smaller10_dir_text_gold\": 809705,\n",
      "    \"smaller20_dir_icon_gold\": 1186,\n",
      "    \"smaller20_dir_image_gold\": 234,\n",
      "    \"smaller20_dir_linebox_gold\": 17094,\n",
      "    \"smaller20_dir_text_gold\": 30549\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# print(stat_dict)\n",
    "print(json.dumps(stat_dict, indent=4,sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "漏报数目：14190\n",
      "ratio<1 | ratio<10 | ratio<20 | ratio<50 | ratio>50\n",
      "0\\4333\\2075\\3690\\4092\n",
      "0.0\\0.30535588442565187\\0.14622973925299507\\0.26004228329809725\\0.28837209302325584\n"
     ]
    }
   ],
   "source": [
    "print(f'漏报数目：{len(miss_list)}')\n",
    "miss_len = len(miss_list)\n",
    "count_smaller_1 = 0\n",
    "count_smaller_10 = 0\n",
    "count_smaller_20 = 0\n",
    "count_smaller_50 = 0\n",
    "count_greater_50 = 0\n",
    "for a in miss_list:\n",
    "    w = abs(a[2] -a[0])\n",
    "    h = abs(a[3] -a[1])\n",
    "    ratio = max(w/h, h/w)\n",
    "    if(ratio<1):\n",
    "        count_smaller_1+=1\n",
    "    elif(ratio<10):\n",
    "        count_smaller_10+=1\n",
    "    elif(ratio<20):\n",
    "        count_smaller_20+=1\n",
    "    elif(ratio<50):\n",
    "        count_smaller_50+=1\n",
    "    else:\n",
    "        count_greater_50+=1\n",
    "print(f'ratio<1 | ratio<10 | ratio<20 | ratio<50 | ratio>50')\n",
    "print(f'{count_smaller_1}\\{count_smaller_10}\\{count_smaller_20}\\{count_smaller_50}\\{count_greater_50}')\n",
    "print(f'{count_smaller_1/miss_len}\\{count_smaller_10/miss_len}\\{count_smaller_20/miss_len}\\{count_smaller_50/miss_len}\\{count_greater_50/miss_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.labelme 2 sa_subcate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'D:\\sa_data\\sa_coco_1\\labelme\\labelme_json'\n",
    "dir = 'D:\\sa_data\\sa_coco_1\\labelme\\labelme_json'\n",
    "names = os.listdir(dir)\n",
    "cls = set()\n",
    "for name in names:\n",
    "    ins = read_json(pathj(dir, name))\n",
    "    for one in ins['shapes']:\n",
    "        cls.add(one['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h_segline', 'v_segline', 'tab', 'icon_text', 'linebox', 'track', 'mohu', 'inputbox', 'scrollbar_slider']\n"
     ]
    }
   ],
   "source": [
    "cls_name = list(cls)\n",
    "cls_3 =set(['icon','text','image'])\n",
    "cls_name_need = list(cls - cls_3)\n",
    "print(cls_name_need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.各个细类别的recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'D:\\sa_data\\sa_coco_1\\labelme\\comps_linebox_subcate'\n",
    "names = os.listdir(dir)\n",
    "cls_name_need = ['inputbox', 'v_segline', 'tab', 'track', \n",
    "    'linebox', 'h_segline', 'scrollbar_slider']\n",
    "\n",
    "gold_dict ={} #每个类别gt的数量\n",
    "for name in cls_name_need:\n",
    "    gold_dict[name] = 0\n",
    "# cls = set()\n",
    "for name in names:\n",
    "    ins = read_json(pathj(dir, name))\n",
    "    for name in cls_name_need:\n",
    "        gold_dict[name] += len(ins[name])\n",
    "        # cls.add(one['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = r'D:\\sa_data\\f36_exps\\20221124_aware_hardnms_conf10_iou50\\Element_grabbing\\grabbing_evaluation\\labelme\\grabbing_predict'\n",
    "need_name  = ['linebox']\n",
    "pred_bboxes =[]\n",
    "for pred in os.listdir(predicts):\n",
    "    pred_ins = read_json(pathj(predicts, pred))\n",
    "    for name in need_name:\n",
    "        try:\n",
    "            if(len(pred_ins[name])==0):\n",
    "                continue\n",
    "            else:\n",
    "                for box_dict in pred_ins[name]:\n",
    "                    pred_bboxes.append(box_dict[\"location\"])\n",
    "        except:\n",
    "            print('KeyError')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"h_segline\": 7746,\n",
      "    \"inputbox\": 14191,\n",
      "    \"linebox\": 7497,\n",
      "    \"scrollbar_slider\": 6900,\n",
      "    \"tab\": 16654,\n",
      "    \"track\": 4522,\n",
      "    \"v_segline\": 27517\n",
      "}\n",
      "115494\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(gold_dict ,indent=4, sort_keys=True))\n",
    "gold_dict.items()\n",
    "# print(sum(gold_dict.items()))\n",
    "print(len(pred_bboxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(a, b):\n",
    "    # 计算两个检测框之间的iou\n",
    "    w_a = a[2] - a[0]\n",
    "    h_a = a[3] - a[1]\n",
    "    w_b = b[2] - b[0]\n",
    "    h_b = b[3] - b[1]\n",
    "\n",
    "    area_a = w_a * h_a\n",
    "    area_b = w_b * h_b\n",
    "\n",
    "    w = min(b[2], a[2]) - max(b[0], a[0])\n",
    "    h = min(b[3], a[3]) - max(b[1], a[1])\n",
    "\n",
    "    if w <= 0 or h <= 0:\n",
    "        return 0\n",
    "\n",
    "    area_c = w * h\n",
    "\n",
    "    return area_c / (area_a + area_b - area_c)\n",
    "\n",
    "import numpy as np\n",
    "def iou_np(boxes0: np.ndarray, boxes1: np.ndarray):\n",
    "    \"\"\" 计算多个边界框和多个边界框的交并比\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    boxes0: `~np.ndarray` of shape `(A, 4)`\n",
    "        边界框\n",
    "\n",
    "    boxes1: `~np.ndarray` of shape `(B, 4)`\n",
    "        边界框\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    iou: `~np.ndarray` of shape `(A, B)`\n",
    "        交并比\n",
    "    \"\"\"\n",
    "    A = boxes0.shape[0]\n",
    "    B = boxes1.shape[0]\n",
    "\n",
    "    xy_max = np.minimum(boxes0[:, np.newaxis, 2:].repeat(B, axis=1),\n",
    "                        np.broadcast_to(boxes1[:, 2:], (A, B, 2)))\n",
    "    xy_min = np.maximum(boxes0[:, np.newaxis, :2].repeat(B, axis=1),\n",
    "                        np.broadcast_to(boxes1[:, :2], (A, B, 2)))\n",
    "\n",
    "    # 计算交集面积\n",
    "    inter = np.clip(xy_max-xy_min, a_min=0, a_max=np.inf)\n",
    "    inter = inter[:, :, 0]*inter[:, :, 1]\n",
    "\n",
    "    # 计算每个矩阵的面积\n",
    "    area_0 = ((boxes0[:, 2]-boxes0[:, 0])*(\n",
    "        boxes0[:, 3] - boxes0[:, 1]))[:, np.newaxis].repeat(B, axis=1)\n",
    "    area_1 = ((boxes1[:, 2] - boxes1[:, 0])*(\n",
    "        boxes1[:, 3] - boxes1[:, 1]))[np.newaxis, :].repeat(A, axis=0)\n",
    "\n",
    "    return inter/(area_0+area_1-inter)\n",
    "\n",
    "def get_iou_thresh(a):\n",
    "    # 文本采用动态iou，最大可以到MAX_IOU，对于小目标最小iou可以到0.1。\n",
    "    w_a = a[2] - a[0]\n",
    "    h_a = a[3] - a[1]\n",
    "    area = (w_a + 1) * (h_a + 1)\n",
    "    iou_thresh = min((area+50)/500, 0.5)\n",
    "    return iou_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'D:\\sa_data\\sa_coco_1\\labelme\\comps_linebox_subcate'\n",
    "predicts = r'D:\\sa_data\\f36_exps\\20221124_aware_hardnms_conf10_iou50\\Element_grabbing\\grabbing_evaluation\\labelme\\grabbing_predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-be917942b907>:19: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predcit_status = np.zeros(len(dt_per_img), dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tps_dict = {}\n",
    "for name in cls_name_need:\n",
    "    tps_dict[name+'_tp'] = 0\n",
    "for name in os.listdir(dir): #每个文件进行对比\n",
    "    pred_ins = read_json(pathj(predicts, name))\n",
    "    gold_ins = read_json(pathj(dir, name))\n",
    "    dt_per_img = []\n",
    "    gt_per_img = []\n",
    "    dt = pred_ins['linebox']\n",
    "    for e in dt:\n",
    "        dt_per_img.append({'box':e['location'], 'label': 'linebox'})\n",
    "    for name in cls_name_need:\n",
    "        gt = gold_ins[name]\n",
    "        # gold_dict[name] += len(ins[name])\n",
    "        for g in gt:\n",
    "            gt_per_img.append({'box':g['location'], 'label':name})\n",
    "\n",
    "    #一张图的 dt和gt都有了\n",
    "    predcit_status = np.zeros(len(dt_per_img), dtype=np.int)\n",
    "    for gt in gt_per_img:\n",
    "        dyn_iou = get_iou_thresh(gt['box'])\n",
    "        iou_thresh = min(0.5, dyn_iou)\n",
    "        count = -1\n",
    "        for dt in dt_per_img:\n",
    "            count+=1\n",
    "            if predcit_status[count] == 0:\n",
    "                cur_iou = iou(gt['box'], dt['box'])\n",
    "                cur_gt_label = gt['label']\n",
    "                if cur_iou > iou_thresh:\n",
    "                    tps_dict[cur_gt_label+'_tp']+=1\n",
    "                    predcit_status[count] = 1\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            else: \n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"h_segline_tp\": 3775,\n",
      "    \"inputbox_tp\": 14024,\n",
      "    \"linebox_tp\": 7339,\n",
      "    \"scrollbar_slider_tp\": 6280,\n",
      "    \"tab_tp\": 16606,\n",
      "    \"track_tp\": 3324,\n",
      "    \"v_segline_tp\": 19269\n",
      "}\n",
      "{\n",
      "    \"h_segline\": 7746,\n",
      "    \"inputbox\": 14191,\n",
      "    \"linebox\": 7497,\n",
      "    \"scrollbar_slider\": 6900,\n",
      "    \"tab\": 16654,\n",
      "    \"track\": 4522,\n",
      "    \"v_segline\": 27517\n",
      "}\n",
      "115494\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(tps_dict, indent=4,sort_keys=True))\n",
    "print(json.dumps(gold_dict ,indent=4, sort_keys=True))\n",
    "print(len(pred_bboxes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
